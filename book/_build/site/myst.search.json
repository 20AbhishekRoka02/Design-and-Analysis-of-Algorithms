{"version":"1","records":[{"hierarchy":{"lvl1":"Chapter 1: Algorithm"},"type":"lvl1","url":"/chapter-1-alogrithm","position":0},{"hierarchy":{"lvl1":"Chapter 1: Algorithm"},"content":"","type":"content","url":"/chapter-1-alogrithm","position":1},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Algorithm"},"type":"lvl2","url":"/chapter-1-alogrithm#algorithm","position":2},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Algorithm"},"content":"“It is a set of well defined steps, which are followed to solve a problem”\n\nExample:\n\nBrushing Teeth\n\nMaking Tea\n\nDetermine best profit for thief in a Knapsack\n\nHelp salesperson travel all cities with minimal cost to meet monthly targets","type":"content","url":"/chapter-1-alogrithm#algorithm","position":3},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl3","url":"/chapter-1-alogrithm#characteristics-of-an-algorithm","position":4},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"There are 5 key characteristics of an algorithm:-","type":"content","url":"/chapter-1-alogrithm#characteristics-of-an-algorithm","position":5},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"1. Definiteness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl4","url":"/chapter-1-alogrithm#id-1-definiteness","position":6},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"1. Definiteness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"Every step is meaningful and unambiguous for the reader.\n\nFor example: Increase value of x by 1, instead of make x bigger.","type":"content","url":"/chapter-1-alogrithm#id-1-definiteness","position":7},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"2. Finiteness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl4","url":"/chapter-1-alogrithm#id-2-finiteness","position":8},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"2. Finiteness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"Every algorithm must have finite number of steps.","type":"content","url":"/chapter-1-alogrithm#id-2-finiteness","position":9},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"3. Input","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl4","url":"/chapter-1-alogrithm#id-3-input","position":10},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"3. Input","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"An algorithm must accept zero or more inputs.","type":"content","url":"/chapter-1-alogrithm#id-3-input","position":11},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"4. Output","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl4","url":"/chapter-1-alogrithm#id-4-output","position":12},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"4. Output","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"It must produce atleast one output.","type":"content","url":"/chapter-1-alogrithm#id-4-output","position":13},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"5. Effectiveness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"type":"lvl4","url":"/chapter-1-alogrithm#id-5-effectiveness","position":14},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"5. Effectiveness","lvl3":"Characteristics of an Algorithm","lvl2":"Algorithm"},"content":"It must be followed easily, even with pen and paper.","type":"content","url":"/chapter-1-alogrithm#id-5-effectiveness","position":15},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Pseudo Code"},"type":"lvl2","url":"/chapter-1-alogrithm#pseudo-code","position":16},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Pseudo Code"},"content":"It is the most effective way to represent an algorithm.\n\nIt is in normal english language.\n\nIt is written as a sequence of steps.\n\nExample:","type":"content","url":"/chapter-1-alogrithm#pseudo-code","position":17},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Psuedo code for making a Tea","lvl2":"Pseudo Code"},"type":"lvl3","url":"/chapter-1-alogrithm#psuedo-code-for-making-a-tea","position":18},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Psuedo code for making a Tea","lvl2":"Pseudo Code"},"content":"Steps are as follows:-\n\nGet:\n\nA \\frac{3}{4} cup of drinking water\n\nA vessel (patila)\n\nA \\frac{1}{2} tea spoon of tea leaves (chai patti)\n\nGinger (1 gram)\n\n2 tea spoons of sugar\n\nA \\frac{1}{2} cup of milk\n\nFilter (channi)\n\nLight the stove to medium flame and place vessel.\n\nPut \\frac{3}{4} cup of water.\n\nAdd tea leaves, crushed ginger and sugar.\n\nWait till water begins to boil.\n\nAdd milk\n\nOnce the solution begins to boil, and comes to the brim of the vessel, turn off the flame.\n\nNow, filter the tea from vessel to cup.\n\nThis is how we write Pseudo Code of a problem!","type":"content","url":"/chapter-1-alogrithm#psuedo-code-for-making-a-tea","position":19},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Performance Analysis"},"type":"lvl2","url":"/chapter-1-alogrithm#performance-analysis","position":20},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl2":"Performance Analysis"},"content":"Actually, we have discussed only way of making a tea.\n\nHere, we have allocated our ingredients before, then prepared the tea.\n\nSo, it make our process faster, but used up too many resources such as:\n\n2 cups for water and milk\n\n3 tea spoons for tea leaves and sugar\n\nInstead of using 2 cups, we can use just 1 cup to put water first, then, milk.\n\nWe can solve the same approach the other way, where we will access ingredients and resources when required, no pre-allocations!\n\nNow, this will save our resources, but increase time spent to make a tea, because there will be extra time to get resources and ingredients.\n\nSimilarly, for other approaches, to make the same tea, we analyse their performance based on their:\n\nTime, and\n\nSpace\n\nAnd, this is what we study in this subject, when we go for analysis part of an algorithm.\n\nWe look for their:\n\nTime Complexity\n\nIt is the time taken by an algorithm to solve our problem.\n\nSpace Complexity\n\nIt is the space taken by algorithm to solve a problem.","type":"content","url":"/chapter-1-alogrithm#performance-analysis","position":21},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Order of Function","lvl2":"Performance Analysis"},"type":"lvl3","url":"/chapter-1-alogrithm#order-of-function","position":22},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Order of Function","lvl2":"Performance Analysis"},"content":"Sometimes, we compare bunch of algorithms together, some are slower, some are faster, while other takes almost same time and space.\n\nSuppose if we have algorithms A, B, C and D\n\nIf we come with a time comparisons of these algorithms, at an instant, for an input size of 8, we have:\n\nA takes 2 milliseconds\n\nB takes 4 milliseconds\n\nC takes 1 milliseconds\n\nD takes 8 milliseconds\n\nNow, we want to compare it for all input sizes till infinity \\infty\n\nWe will get a vast table for comaprisons among these values, and we plot a graph.\n\n ```\n [ Show graphs of A, B, C and D] as n, n^2, n and 2^n with label for time\n ``` \n\n\n\nIn this figure, A taking linear growth (n), B taking quadratic growth (n^2), C taking contant growth 1, and D taking logarithmic growth (\\log_{2}{n})\n\nBut, NONE of us wants to REMEMBER THIS!\n\nSo, we remember the order of their functions, for example, for the graph like this:\n\nWe say it’s graph of n^2\n\nIn algorithm, it has nested loops, like below, in triangle.for(int i=0; i<5; i++) {\n    for (int j=0; j<i+1; j++) {\n        cout << \"*\";\n    }\n    cout << endl;\n}\n\nfor i in range(1, 6):\n    print(\"*\"*i)\n\n\n\nSimilarly, we have other order of functions defined as follows:\n\nOrder of Function\n\nTheir Meaning\n\n1\n\nConstant time to solve for input of any size\n\nn\n\nrate of growth in time/space same as input size growth\n\nn^2\n\nloop in a loop\n\nn^3\n\nloop in a loop in a loop\n\nlog(n)\n\nProblem getting divided into halves, like binary search\n\nnlog(n)\n\none part grows as n, other as log(n), like merge sort\n\n2^n\n\nTime/Space increasing exponentially, like Travelling Salesperson problem","type":"content","url":"/chapter-1-alogrithm#order-of-function","position":23},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl3","url":"/chapter-1-alogrithm#asymptotic-notation","position":24},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"Our algorithms need not to act the same always.\n\nFor instance, a Binary Search NOT always takes log(n) time to search an element, sometimes, we find element on first check.\n\nIn that case, Order of function would be 1.\n\nSo, our algorithm have:\n\nBest Case Scenario - best performance\n\nWorst Case Scenario - worst performance\n\nAverage Case Scenario - average performance\n\nFor this, we have a mathematical framework, named Asymptotic Notation.","type":"content","url":"/chapter-1-alogrithm#asymptotic-notation","position":25},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Defination","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#defination","position":26},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Defination","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"“It is a mathematical framework which is used to analyse an algorithm for its efficiency as input size (n) grows to infinity (\\infty)”\n\nThere are 3 types of Asymptotic Notations:-\n\nBig O notation (Worst Case)\n\nBig Omega (\\Omega) notation (Best Case)\n\nBig Theta (\\Theta) notation (Average Case)","type":"content","url":"/chapter-1-alogrithm#defination","position":27},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big O Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#big-o-notation","position":28},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big O Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"\n\nIn this figure,\n\nn_{0} - Threshold size of input (i.e. minimum input size, after which functions (algorithms) show their true behavior)f(n) - Our function (algorithm) which is under analysis.cg(n) - Another function (algorithm) having higher rate of growth than our function (algorithm)\n\nDue to above graph, it is also known as Upper Bound.","type":"content","url":"/chapter-1-alogrithm#big-o-notation","position":29},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big O Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#defination-1","position":30},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big O Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"A function f(n) is said to be O(g(n)), if there exists positive constants, c & n_{0}, such that:0 \\leq f(n) \\leq c(g(n)); \\forall n \\geq n_{0}\n\nIt means, how bad our algorithm will perform, as input size grows.\n\nHigh rate of growth, is a bad sign, for an algorithm.","type":"content","url":"/chapter-1-alogrithm#defination-1","position":31},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big Omege (\\Omega) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#big-omege-omega-notation","position":32},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big Omege (\\Omega) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"\n\nIn this figure,\n\nn0 - Threshold size of input (i.e. minimum input size, after which functions (algorithms) show their true behavior).\n\nf(n) - Our function (algorithm) which is under analysis.\n\ncg(n) - Another function (algorithm) having lower rate of growth than our function (algorithm)\n\nDue to above graph, it is also known as Lower Bound.","type":"content","url":"/chapter-1-alogrithm#big-omege-omega-notation","position":33},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big Omege (\\Omega) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#defination-2","position":34},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big Omege (\\Omega) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"A function f(n) is said to be \\Omega(g(n)), if there exists positive constants, c & n_{0}, such that:0 \\leq c(g(n)) \\leq f(n); \\forall n \\geq n_{0}\n\nIt means, how best our algorithm will perform, as input size grows.\n\nLower the rate of growth, is better.","type":"content","url":"/chapter-1-alogrithm#defination-2","position":35},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big Theta (\\Theta) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#big-theta-theta-notation","position":36},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Big Theta (\\Theta) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"\n\nIn this graph,\n\nn_{0} - Threshold size of input (i.e. minimum input size, after which functions (algorithms) show their true behavior)\n\nf(n) -> Our function (algorithm) which is under analysis.\n\nc_{1}g(n) and c_{2}g(n)  -> Another function (algorithm) having higher and lower rate of growth than our function (algorithm)\n\nDue to above graph, it is also known as Tight Bound.","type":"content","url":"/chapter-1-alogrithm#big-theta-theta-notation","position":37},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big Theta (\\Theta) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#defination-3","position":38},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Big Theta (\\Theta) Notation","lvl3":"Asymptotic Notation","lvl2":"Performance Analysis"},"content":"A function f(n) is said to be \\Theta(g(n)), if there exists positive constants, c_{1}, c_{2} & n_{0}, such that:0 \\leq c_{1}(g(n)) \\leq f(n) \\leq c_{2}(g(n)); \\forall n \\geq n_{0}\n\nIt means, average performance of an algorithm.\n\nLies between Upper bound and Lower bound.","type":"content","url":"/chapter-1-alogrithm#defination-3","position":39},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl3","url":"/chapter-1-alogrithm#elementary-data-structures","position":40},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"","type":"content","url":"/chapter-1-alogrithm#elementary-data-structures","position":41},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Stack","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#stack","position":42},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Stack","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":" Add separation \n\n\n\nStack Data Structure\n\nIt is a linear data structure, i.e. elements are accessed one after another, like we have place plates one over another in wedding.\n\nIt has only end for storing (Push) and removing (Pop) an element.\n\nIt operates on LIFO (Last In First Out) principle.\n\nStructure of a stack:\n\nTOP - It is a pointer to the topmost element of the stack.\n\nIN - It is the input direction of an element on the top of the stack.\n\nOUT - It is the output direction of an element from the top of the stack.\n\nStack has Capacity (MAX) associated with it, which shows the maximum elements it can store.","type":"content","url":"/chapter-1-alogrithm#stack","position":43},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Operations on Stack","lvl4":"Stack","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#operations-on-stack","position":44},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Operations on Stack","lvl4":"Stack","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"Push\n\nIt refers to storing element on the top of the stack.\n\nDuring push, TOP get incremented by 1, and we store element at that location, with:TOP++;\nstack[TOP] = element;\n\nPop\n\nIt refers to removing element from the top of the stack.\n\nDuring pop, we simply decrement TOP by 1TOP--;\n\nPeek\n\nIt refers to view the TOP element of stack, with:stack[TOP];\n\nisEmpty\n\nIt checks whether stack is empty or not.\n\nIt returns boolean value: 0 (false) / 1 (true)if (TOP == -1) then\n    return 1; // i.e. stack is empty\nelse\n    return 0; // i.e. stack is not empty\n\nisFull\n\nIt checks whether stack is full or not.\n\nIt returns boolean value: 0 (false) / 1 (true)MAX is the limit of the stack.\n\nif (TOP == MAX) then\n    return 1; // i.e. stack is full\nelse\n    return 0; // i.e. stack is not full","type":"content","url":"/chapter-1-alogrithm#operations-on-stack","position":45},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Queue","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#queue","position":46},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Queue","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"\n\nQueue Data Structure\n\nIt is a linear data structure, i.e. elements are accessed one after another, like we have place plates one over another in wedding.\n\nIt has 2 ends (front and rear).\n\nREAR is for storing elements, and FRONT is for removing elements. (It’s a choice, we can change it)\n\nIt operates on FIFO (First In First Out) principle.\n\nQueue has Capacity associated with it, which is the maximum element it can store in it.\n\nStructure of a Queue:\n\nREAR\n\nIt is a pointer to the rear of the Queue.\n\nIt gets incremented by 1, when we add an element to Queue.\n\nIt stops, when REAR becomes equal to Capacity.\n\nFRONT\n\nIt is a pointer to the front of the Queue.\n\nIt gets incremented by 1, when we remove an element from Queue.\n\nIt stops, when FRONT becomes equal to REAR.","type":"content","url":"/chapter-1-alogrithm#queue","position":47},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Operations on Queue","lvl4":"Queue","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#operations-on-queue","position":48},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Operations on Queue","lvl4":"Queue","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"Enqueue\n\nIt refers to storing element to the REAR of the Queue.\n\nDuring enqueue, REAR get incremented by 1, and we store element at that location, with:REAR++;\nQueue[REAR] = element;\n\nDequeue\n\nIt refers to removing element from the FRONT of the Queue.\n\nDuring dequeue, we simply increment FRONT by 1FRONT++\n\ngetFront\n\nIt refers to view the FRONT element of Queue, with:queue[FRONT];\n\ngetRear\n\nIt refers to view the REAR element of Queue, with:queue[REAR];\n\nisEmpty\n\nIt checks whether Queue is empty or not.\n\nif FRONT > REAR, then Queue is empty.\n\nIt returns boolean value: 0 (false) / 1 (true)if (FRONT > REAR) then\n    return 1; // i.e. Queue is empty\nelse\n    return 0; // i.e. Queue is not empty\n\nisFull\n\nIt checks whether Queue is full or not.\n\nIf REAR is equal to Capacity, then Queue if full.\n\nIt returns boolean value: 0 (false) / 1 (true)CAPACITY is the limit of the stack.\n\nif (REAR == CAPACITY) then\n    return 1; // i.e. queue is full\nelse\n    return 0; // i.e. queue is not full","type":"content","url":"/chapter-1-alogrithm#operations-on-queue","position":49},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#tree","position":50},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"It is a non-linear data structure.\n\nIt is designed as a parent-child relationship, so it is a hierarichal data structure.\n\n\n\nTree Data Structure","type":"content","url":"/chapter-1-alogrithm#tree","position":51},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Terminologies","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#terminologies","position":52},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Terminologies","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"Node - It is a storage unit in tree, which contains values and pointer to predecessor node & successor nodes.\n\n\n\nNode structure\n\nEdge - It is a link between 2 nodes, as A & B are connected by an edge.\n\nParent Node - An immediate predecessor (i.e. previous node) of a node, as C is Parent node of F.\n\nChild Node - An immediate successor (i.e. next node) of a node, as F is Child node of C.\n\nLeaf Node - It is the node which has no further child node, as F is a Leaf node.\n\nSubtree - A tree which is a subset of given tree, see the diagram above.\n\nRoot Node - The topmost node which is the predessor of all nodes.","type":"content","url":"/chapter-1-alogrithm#terminologies","position":53},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Characteristics","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#characteristics","position":54},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Characteristics","lvl4":"Tree","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"Depth of a node\n\nNumber of edges from root to a given node\n\nFor example, Depth of node E is 2, in diagram above.\n\nNumber of Edges\n\nIt is the total number of edges in the tree.\n\nIf number of nodes in a tree are n, then\nnumber\\hspace{2px} of\\hspace{2px} edges, e = n - 1\n\nFor example, there are 7 nodes, and 6 edges in the tree above.\n\nHeight of a Tree\n\nIt is the longest path in the tree, i.e. number of edges from root node to leaf nodes is the highest.\n\nFor example, in the tree above, height of the tree is 2.\n\nDegree\n\nIt is number of children a node has.\n\nFor example, Node B has degree of 2, while leaf nodes has degree of 0.","type":"content","url":"/chapter-1-alogrithm#characteristics","position":55},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl4","url":"/chapter-1-alogrithm#graph","position":56},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"\n\nGraph Data Structure\n\nIt is a non-linear data structure.\n\nUnlike other data structures, there is no hard and fast rule about what must be the first node, placement of node and its traversal.\n\nAny node can participate a graph at a time.\n\nBut, there is only one rule that:\n\nwe must reach all nodes connected to given node using the given edge only once.\n\nSo, keep record of all vertices and edges, we have a set of vertices as V and a set of edges as E.","type":"content","url":"/chapter-1-alogrithm#graph","position":57},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#defination-4","position":58},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Defination","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"A graph, G, is represented as  G = (V, E)  , where, V is set of vertices (nodes), and E is the set of edges\n\nFor example, Social Media.\n\nThere is no rule to add us as a user, every account has equal importance.\n\nBut, when we are a part of an university, we are under an hierarchy (tree data structure), like student to Class Representative to Class Teacher to HOD and so on.","type":"content","url":"/chapter-1-alogrithm#defination-4","position":59},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Types of Graph","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#types-of-graph","position":60},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Types of Graph","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"A graph has various types, on the basis of:\n\nDirection\n\nDirected Graph\n\nUndirected Graph\n\n\n\nLeft: Directed Graph, and Right: Undirected Graph\n\nWeight\n\nWeighted Graph\n\nUnweighted Graph\n\n\n\nLeft: Weighted Graph, and Right: Unweighted Graph","type":"content","url":"/chapter-1-alogrithm#types-of-graph","position":61},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Representation","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"type":"lvl5","url":"/chapter-1-alogrithm#representation","position":62},{"hierarchy":{"lvl1":"Chapter 1: Algorithm","lvl5":"Representation","lvl4":"Graph","lvl3":"Elementary Data Structures","lvl2":"Performance Analysis"},"content":"Diagram\n\n\n\nGraph Representation\n\nAdjancency matrix * Matrix of above diagram\n ```{math}\n \\begin{equation*}\n A = \n \\begin{bmatrix}\n a_{aa} & a_{ab} & a_{ac} & a_{ad} \\\\\n a_{ba} & a_{bb} & a_{bc} & a_{bd} \\\\\n a_{ca} & a_{cb} & a_{cc} & a_{cd} \\\\\n a_{da} & a_{db} & a_{dc} & a_{dd} \n \\end{bmatrix}\n =\n \\begin{bmatrix}\n 0 & 1 & 0 & 1 \\\\\n 1 & 0 & 1 & 1 \\\\\n 0 & 1 & 0 & 1 \\\\\n 1 & 1 & 1 & 0\n \\end{bmatrix}\n \\end{equation*}\n ```\n where $a_{ab}$ means weight of edge joining node A with node B \n\n\n\nAdjacency Matrix of Graph above\n\nHere,\n\nEach edge got a weight of 1\n\n0 (zero) means, there is no edge between those nodes $$\n\\begin{array}{c|cccc}\n   & A & B & C & D \\\\\n\\hline\nA & a_{11} & a_{12} & a_{13} & a_{14} \\\\\nB & a_{21} & a_{22} & a_{23} & a_{24} \\\\\nC & a_{31} & a_{32} & a_{33} & a_{34} \\\\\nD & a_{41} & a_{42} & a_{43} & a_{44}\n\\end{array}  $$ $$\n \\begin{equation*}\n A_{m,n} =\n \\begin{bmatrix}\n a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n a_{m,1} & a_{m,2} & \\cdots & a_{m,n}\n \\end{bmatrix}\n \\end{equation*}\n $$","type":"content","url":"/chapter-1-alogrithm#representation","position":63},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer"},"type":"lvl1","url":"/chapter-2-divide-and-conquer","position":0},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer"},"content":"It is one of the well known problem solving technique, where we breakdown a given problem and solve it.\n\nSuppose we have to find marks of a student from the pile of marksheets (ordered alphabetically), so we can divide the pile into several parts based on starting letter alphabet of the name, like A, B, C ... Z.\n\nTo find marksheet of a student named Aditya, we will access Part A (containing marks of students name starting with A) only, and not required to access other part of the pile. Then we will find the marksheet of student.","type":"content","url":"/chapter-2-divide-and-conquer","position":1},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl2":"Working of Divide & Conquer"},"type":"lvl2","url":"/chapter-2-divide-and-conquer#working-of-divide-conquer","position":2},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl2":"Working of Divide & Conquer"},"content":"It is a 3 step process\n\nDivide\n\nDivide a given problem into separate subproblems\n\nSeparate subproblems means, it must be independent from other subproblems.\n\nFor example, in pile of marksheets, to find marks of Aditya, we will access only that part of pile which is starting with A.\n\nThere will be no benefit to conduct search on rest of the pile.\n\nSimilarly, for Gaurav, we will access starting with G part of the pile.\n\nConquer\n\nNow, we solve the given subproblems independently and get its solution.\n\nMerge\n\nHere, we merge the solution of subproblems.\n\nIt is an optional step\n\nLike, for searching Aditya’s marksheet, we do not have to perform any merge operation\n\nBut we will merge solutions in problems like sorting elements of an array with Merge Sort.","type":"content","url":"/chapter-2-divide-and-conquer#working-of-divide-conquer","position":3},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Advantages","lvl2":"Working of Divide & Conquer"},"type":"lvl3","url":"/chapter-2-divide-and-conquer#advantages","position":4},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Advantages","lvl2":"Working of Divide & Conquer"},"content":"Easy to implement\n\nAs we have to divide a problem into subproblems and solve them independently.\n\nThere is no overlapping of subproblems like we will have in Dynamic Programming problems.\n\nParallelism\n\nHere, we can compute solution of independent subproblems in parallel.\n\nEasy to design solutions\n\nIt’s solution can be implemented recursively, which will make designing easy.","type":"content","url":"/chapter-2-divide-and-conquer#advantages","position":5},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Disadvantages","lvl2":"Working of Divide & Conquer"},"type":"lvl3","url":"/chapter-2-divide-and-conquer#disadvantages","position":6},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Disadvantages","lvl2":"Working of Divide & Conquer"},"content":"Overhead\n\nWe have to compute solutions for all sub problems independently.\n\nAs there is no overlapping in sub problems, so solution of one cannot be used in a solution of another sub problem.\n\nMemory Consumption\n\nAs we have to compute solutions for every sub problem, and there is no overlapping.\n\nThis lead to memory consumption for storage of solutions of them, so we can merge them as a single solution, later on.","type":"content","url":"/chapter-2-divide-and-conquer#disadvantages","position":7},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Applications","lvl2":"Working of Divide & Conquer"},"type":"lvl3","url":"/chapter-2-divide-and-conquer#applications","position":8},{"hierarchy":{"lvl1":"Chapter 2: Divide and Conquer","lvl3":"Applications","lvl2":"Working of Divide & Conquer"},"content":"We will discuss following applications of Divide and Conquer approach in this book\n\nBinary Search\n\nQuick Sort\n\nMerge Sort\n\nStrassen’s Matrix Multiplication Algorithm","type":"content","url":"/chapter-2-divide-and-conquer#applications","position":9},{"hierarchy":{"lvl1":"Binary Search"},"type":"lvl1","url":"/chapter-2-1-binary-search","position":0},{"hierarchy":{"lvl1":"Binary Search"},"content":"It is a Divide and Conquer algorithm, where we will divide a problem (here, a sorted array) into 2 halves in each iteration.","type":"content","url":"/chapter-2-1-binary-search","position":1},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Requirements"},"type":"lvl2","url":"/chapter-2-1-binary-search#requirements","position":2},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Requirements"},"content":"A sorted array\n\nConstant access time to any part of array","type":"content","url":"/chapter-2-1-binary-search#requirements","position":3},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Working"},"type":"lvl2","url":"/chapter-2-1-binary-search#working","position":4},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Working"},"content":"Suppose we have given an arrayPlace array here\n\nand, we have to search element valued 1.\n\nSo, we have,\n\nlength of array, n = 7\n\nlowest index, low = 0\n\nhighest index, high = 6\n\nelement to find, key = 1\n\nNow, we calculate mid index as:\nmid = \\frac{0 + 6}{2}\n\nIt will be a floor division i.e., if \\frac{3}{2} = 1.5, then answer will be 1\n\nhere, mid = 3\n\nSo, element at index mid (i.e. 3) is valued 4.arr[mid] = 4\n\nNow, we make comparisonsif key < arr[mid]:\n    set high = mid - 1 \nelse if key > arr[mid]:\n    set low = mid + 1\nelse:\n    return mid\n\nFor now, key < arr[mid], so we set high = 2.\n\nSo, low = 0, high = 2, again calculate mid, now mid = \\frac{0+2}{2} = 1\n\nNow, arr[mid] = 2, and key < 2, therefore high = mid - 1 (i.e. 0)\n\nlow = 0 & high = 0\n\nCalculating mid,  mid = \\frac{0+0}{2} = 0\n\narr[0] = 1 & key = 1\n\nTherefore, element is found at index 0\n\nSuppose, instead of 1, if we search for -2.\n\nAt this point, we will be doing, high = mid - 1 (i.e. -1)\n\nNow, high < low, which will be invalid case for this algorithm & we will return -1 i.e. Not Found!","type":"content","url":"/chapter-2-1-binary-search#working","position":5},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Algorithm of Binary Search"},"type":"lvl2","url":"/chapter-2-1-binary-search#algorithm-of-binary-search","position":6},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Algorithm of Binary Search"},"content":"Set low = 0, high = n - 1 and key\nwhile low <= high; do\n    Calculate mid = (low + high) / 2\n\n    if key == arr[mid]; then\n        return mid\n    else if key < arr[mid]; then\n        high = mid - 1\n    else:\n        low = mid + 1\n\nreturn - 1\n\nAbove is the Iterative Approach of solving this problem.","type":"content","url":"/chapter-2-1-binary-search#algorithm-of-binary-search","position":7},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Time Complexity"},"type":"lvl2","url":"/chapter-2-1-binary-search#time-complexity","position":8},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Time Complexity"},"content":"Best Case is \\Omega(1) i.e. on first attempt we got arr[mid] == key.\n\nWorst Case is O( \\log n) i.e. even though an element is not found, but we got \\log n comparisons, like for 7 elements above, log_{2}(7) = 2.807 \\approx 3 comparisons to get our solution\n\nAnd, Average Case is \\Theta(\\log n) i.e. for an average input size.","type":"content","url":"/chapter-2-1-binary-search#time-complexity","position":9},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Space Complexity (Auxillary Space)"},"type":"lvl2","url":"/chapter-2-1-binary-search#space-complexity-auxillary-space","position":10},{"hierarchy":{"lvl1":"Binary Search","lvl2":"Space Complexity (Auxillary Space)"},"content":"For iterative approach, it is O(1), as we are not allocating any new memory space at run time.\n\nFor recursive approach, we got O(\\log n), as we push the instance of function on to stack memory for each recursive call.\n\nAs \\log_{2}(7) = 2.807 \\approx 3, on 3rd push of stack, we have output as either found or not found.","type":"content","url":"/chapter-2-1-binary-search#space-complexity-auxillary-space","position":11},{"hierarchy":{"lvl1":"Quick Sort"},"type":"lvl1","url":"/chapter-2-2-quick-sort","position":0},{"hierarchy":{"lvl1":"Quick Sort"},"content":"A Divide and Conquer algorithm where we will sort a given array by picking a Pivot element & a Partitioning function to rearrange elements around pivot.\n\nIt has 2 main components:\n\nPivot - an element of given array\n\nPartitioning algorithm - to re-arrange elements around pivot.\n\nSteps are:\n\nChoose a Pivot\n\nAn element is selected around which Partitioning algorithm will re-arrange elements of given array or sub-array.\n\nIt is selected by using any of the method given below:\n\nFirst / Last element selection\n\nRandom element selection\n\nCalculate the median\n\nPartitioning the array / sub array\n\nThis algorithm will re-arrange elements around Pivot.\n\nThere are 2 famous Partitioning:\n\nNaive Partition\n\nLoumuto Partition\n\nRecursive Call\n\nThis will make recursive call to Quick Sort algorithm on both sides of Pivot.\n\nBase Case\n\nThe recursion halts when we have only one element left in the array","type":"content","url":"/chapter-2-2-quick-sort","position":1},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Working"},"type":"lvl2","url":"/chapter-2-2-quick-sort#working","position":2},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Working"},"content":"Suppose we have an unsorted arrayPlace image of unsorted array here\n\nNow, we choose a Pivot element, in our case, we will choose “The Last Element”, (here index 4)\n\nSo, let’s highlight it.Unsorted array with highlighted element at index 4 goes here\n\nNow, we set i = j = 0, and iterate j from 0 to 3 (i.e. high - 1)\n\nif arr[j] < pivot, we will swap elements at i and j & increment i by 1arr[i], arr[j] = arr[j], arr[i]\n\n// increment i by 1\ni++\n\nHere is the iteration:\n\nj\n\ni\n\narr[j]\n\nPivot\n\narr[j] < Pivot\n\nAction\n\n0\n\n0\n\n3\n\n0\n\nFalse\n\n\n\n1\n\n0\n\n8\n\n0\n\nFalse\n\n\n\n2\n\n0\n\n2\n\n0\n\nFalse\n\n\n\n3\n\n0\n\n4\n\n0\n\nFalse\n\n\n\nAt the end of loop, we swap arr[high] (pivot) and arr[i]// arr[high] is Pivot element\narr[high], arr[i] = arr[i], arr[high] \n\nNow our looks like this:Place diagram of Pivot i.e. 0 in the array\n0,8,2,4,3\n\nNow, we will partition array into left and right halfShow the right halft and left half\n\nLeft half - There is no array\n\nRight half - we have [8,2,4,3]\n\nChoose Last element as Pivot (i.e. arr[4] = 3)\n\nWe set\n\nlow = 1\n\nhigh = 4\n\ni = 1\n\nj = 1\n\nPivot = arr[high] (i.e. 3)\n\nAs we did in step 5,\n\nSet i = j = low (i.e. 1)\n\nIterate j from low to high - 1\n\nIf arr[j] < Pivot, swap arr[i] and arr[j]\n\nj\n\ni\n\narr[j]\n\nPivot\n\narr[j] < Pivot\n\nAction\n\n1\n\n1\n\n8\n\n3\n\nFalse\n\n\n\n2\n\n1\n\n2\n\n3\n\nTrue\n\nSwap arr[i] and arr[j]\n\nNow sub array will be:Picture of 2,8,4,3\n\nNow, i = 2\n\nNow, let’s get back to the table\n\nj\n\ni\n\narr[j]\n\nPivot\n\narr[j] < Pivot\n\nAction\n\n3\n\n2\n\n4\n\n3\n\nFalse\n\n\n\nNow, we swap arr[j] with arr[high], & our array.Pivot of [2,3,4,8]\n\nNow, we divide it to left half and right halfPicture of [2,3,4,8] -> 2 and -> [4,8]\n\nAS there is only one element on left, we will not perform sorting there.\n\nOn the right, we havePicture of [4, 8v(highlighted)]\n\nPick Pivot as hight = 4\n\nAgain,\n\nlow = 3\n\nhigh = 4\n\ni = j = low (i.e. 3)\n\nPivot = 8 (i.e. arr[high])\n\nWe iterate j for 3 only\n\nj\n\ni\n\narr[j]\n\nPivot\n\narr[j] < Pivot\n\nAction\n\n3\n\n3\n\n4\n\n8 False\n\n\n\nNow, when we divide this array now,Picture of [4,8] -> 4 and -> 8\n\nWe will not perform sorting on left, and right.\n\nLet’s see our array nowPicture of [0,2,3,4,8]\n\nWe have sorted it in the steps, we have discussed till now.Picture of complete Quick Sort array view divide and conquer and merge","type":"content","url":"/chapter-2-2-quick-sort#working","position":3},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Algorithm"},"type":"lvl2","url":"/chapter-2-2-quick-sort#algorithm","position":4},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Algorithm"},"content":"This algorithm is divided into 2 parts:\n\nQuick Sort\n\nwhich will recursive call itself.\n\nPartition Function\n\nwhich will re-arrange around the PivotQuickSort(arr, low, high):\n    if low < high:\n        p = partition(arr, low, high)\n\n        // Quick Sort left sub array\n        QuickSort(arr, low, p - 1) \n\n        // Quick Sort right sub array\n        QuickSort(arr, p + 1, high)\n\npartition(arr, low, high):\n    i = low - 1\n\n    // Picking last element as Pivot\n    pivot = arr[high]\n\n    for j from low to high - 1:\n         if arr[j] < pivot:\n            i++\n\n            // Swapping elements at arr[i] and arr[j]\n            arr[i], arr[j] = arr[j], arr[i]\n    i++\n    arr[i], arr[high] = arr[high], arr[i]\n    return i","type":"content","url":"/chapter-2-2-quick-sort#algorithm","position":5},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Time Complexity"},"type":"lvl2","url":"/chapter-2-2-quick-sort#time-complexity","position":6},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Time Complexity"},"content":"Worst Case is O(n^2) because of following cases:-\n\nArray may be already sorted or reverse sorted\n\nPicking smallest or largest element by value as a Pivot\n\nPicking First/Last element as Pivot (I want to say something about this)\n\nSome suggest picking Median value as Pivot can solve a problem, but calculating median each time will create an overhead which will make it O(n^2) again\n\nSo, O(n^2) is not a case of Pivot only, but type of input we got i.e. how elements are arranged in a given array.\n\nBest Case is \\Omega(n \\log n), and Average Case is \\Theta(n \\log n), let discuss how:\n\nn, because at every level, there is a sub array which will sum to n elements of the original array.\n\n\\log n, because there will be roughly \\log n recursion calls\n\nlike, we have 5 elements, then \\log_{2} 5 = 2.3219, which is between 2 & 3, and we have 3 recursion calls, in above example","type":"content","url":"/chapter-2-2-quick-sort#time-complexity","position":7},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Space Complexity (Auxillary Space)"},"type":"lvl2","url":"/chapter-2-2-quick-sort#space-complexity-auxillary-space","position":8},{"hierarchy":{"lvl1":"Quick Sort","lvl2":"Space Complexity (Auxillary Space)"},"content":"O(n) - when there is imbalanced partitioning, i.e. pivot is the smallest/largest element of the given sub array, like shown belowPicture of imbalanced partitioning examples\n\nO(\\log n) - when there is balanced partitioning i.e. pivot is roughly the median element of the array.","type":"content","url":"/chapter-2-2-quick-sort#space-complexity-auxillary-space","position":9},{"hierarchy":{"lvl1":"Merge Sort"},"type":"lvl1","url":"/chapter-2-3-merge-sort","position":0},{"hierarchy":{"lvl1":"Merge Sort"},"content":"It is a Divide and Conquer algorithm which first divides given array into 2 halves, until only single element left & then, begin merging them into sorted array.\n\nIt have following steps:-\n\nDivide\n\nHere, we divide array into 2 halves by calculating the mid element.\n\nSo, one array is from low to mid, and other is from mid + 1 to high.\n\nWe stop dividing further, when only 1 element left in the array.\n\nConquer\n\nHere, we sort the 2 sub arrays, by compariing them, elements by elements.\n\nSmaller element gets inserted to the end of the sorted array. (i.e. we have to create another empty array, where we will place elements in sorted manner)\n\nWhen one array ends, the remaining part of the other array gets merged directly to the end of sorted array\n\nMerge\n\nOnce we reach the level, where only 1 element is left in both arrays, we begin to merge them, upto the 1st recursive call of the Merge Sort function.","type":"content","url":"/chapter-2-3-merge-sort","position":1},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Working"},"type":"lvl2","url":"/chapter-2-3-merge-sort#working","position":2},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Working"},"content":"Let me explain it with example, so the things will make sense. Then, you can define merge sort in your words.\n\nSuppose we have given an arrayPlace image of unsorted array\n\nHere, low = 0, high = 4, we calculate midmid = \\frac{low + high}{2}\n\nIt will be a floor division\nSo,\nmid = \\frac{0 + 4}{2} = \\frac{4}{2} = 2\n\nNow, we got:Picture of left and right part of the array\n\nNow, we calculate mid & divide them independently:Place rest of the diagram\n\nNow, it will look likeShow complete diagram of Merge Sort\n\nLet’s start merging from Level 3\nSo, we have:Place picture of 3 and 8\n\nOn compare & merge, we haveimage of sorted array\n\nNow, in Level 2, we first work on left part\n\nLet’s compare & merge\n\nis 3 < 2 ? FalsePicture of sorted array\n\nNow only left array is remaining. So we merge it directly.\n\nWe get:Place picture here\n\nOn right half of Level 2, we have:Picture of 4 and 0\n\nOn level 1, we have:Place picture of arrays\n\nLet’s compare and merge:\n\ni\n\nj\n\narr[i]\n\narr[j]\n\narr[i] < arr[j]\n\nsorted_array\n\n0\n\n0\n\n2\n\n0\n\nFalse\n\n0\n\n0\n\n1\n\n2\n\n4\n\nTrue\n\n0 2\n\n1\n\n1\n\n3\n\n4\n\nTrue\n\n0 2 3\n\n2\n\n1\n\n8\n\n4\n\nFalse\n\n0 2 3 4Sorted array\n\nAt Level 0, we have our sorted array now,Image of sorted array","type":"content","url":"/chapter-2-3-merge-sort#working","position":3},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Algorithm"},"type":"lvl2","url":"/chapter-2-3-merge-sort#algorithm","position":4},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Algorithm"},"content":"It is divided into 2 parts:\n\nMerge Sort Function which will make recursive call.\n\nMerge Function which will merge the sorted halves.MergeSort(arr, low, high):\n    if low < high:\n        mid = (low + high) / 2\n\n        // Merge Sort on Left half\n        MergeSort(arr, low, mid)\n\n        // Merge Sort on Right half\n        MergeSort(arr, mid + 1, high)\n\n        // Merging both halves\n        Merge(arr, low, mid, high)\n\nMerge(arr, low, mid, high):\n    size_of_left_array = (mid - low) + 1\n    size_of_right_array = (high - mid) + 1\n    total_size = size_of_left_array + size_of_right_array\n\n    // Create Sorted array of total_size, fill with 0s\n    Create sorted_array [ 0 ... total_size - 1]\n\n    while i <= mid & j <= high; do\n\n        if arr[i] <= arr[j]; then\n            sorted_array[k] = arr[i]\n            k++\n            i++\n        else:\n            sorted_array[k] = arr[j]\n            k++\n            j++\n    \n    if i == mid + 1; then\n        while j <= high; do\n            sorted_array[k] = arr[j]\n            k++\n            j++\n    else:\n        sorted_array[k] = arr[i]\n        k++\n        i++","type":"content","url":"/chapter-2-3-merge-sort#algorithm","position":5},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Time Complexity"},"type":"lvl2","url":"/chapter-2-3-merge-sort#time-complexity","position":6},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Time Complexity"},"content":"For Best, Worst and Average cases, it is n \\log n\n\n\\log n - as each time we are dividing array into \\frac{n}{2}\n\nn - for merging 2 sorted halves","type":"content","url":"/chapter-2-3-merge-sort#time-complexity","position":7},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Space Compelxity"},"type":"lvl2","url":"/chapter-2-3-merge-sort#space-compelxity","position":8},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Space Compelxity"},"content":"It is O(n), as there are n elements in the array.","type":"content","url":"/chapter-2-3-merge-sort#space-compelxity","position":9},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Recurrence Relation"},"type":"lvl2","url":"/chapter-2-3-merge-sort#recurrence-relation","position":10},{"hierarchy":{"lvl1":"Merge Sort","lvl2":"Recurrence Relation"},"content":"T(n) =\n\\begin{cases}\n\\Theta(1); & n = 1 \\\\\n2T\\left(\\frac{n}{2}\\right) + \\Theta(n); & n > 1\n\\end{cases}","type":"content","url":"/chapter-2-3-merge-sort#recurrence-relation","position":11},{"hierarchy":{"lvl1":"Strassen’s Matrix Multiplication"},"type":"lvl1","url":"/chapter-2-4-strassen-matrix-multiplication","position":0},{"hierarchy":{"lvl1":"Strassen’s Matrix Multiplication"},"content":"Suppose we have two 2 \\times 2 matricesA =\n    \\begin{bmatrix}\n    a_{11} & a_{12} \\\\\n    a_{21} & a_{22}\n    \\end{bmatrix}\n    \\;\\&\\;\n    B =\n    \\begin{bmatrix}\n    b_{11} & b_{12} \\\\\n    b_{21} & b_{22}\n    \\end{bmatrix}\n\nNow,A \\times B =\n    \\begin{bmatrix}\n    a_{11}b_{11}+a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\\n    a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22}\n    \\end{bmatrix}\n\nHere, we have total 8 multiplications to perform.\n\nIt generally takes Time Complexity of O(n^3).\n\nStrassen matrix multiplication makes the number of multiplications to 7.\n\nIt reduces time complexity to O(n^{\\log_2 7}) \\approx O(n^{2.81})\n\nSteps of Strassen’s Matrix Multiplication:\n\nDivide\n\nIf size of both martices are  1 \\times 1 , then we return the multiplication of them.\n\nOtherwise, we breakdown it to 4 matrices of size  \\frac{n}{2} \\times \\frac{n}{2} \n\nConquer\n\nFor  \\frac{n}{2} \\times \\frac{n}{2}  matrix, we compute Strassen’s 7 multiplications, which I will show in few moments.\n\nThen, we compute C_{11}, \\space C_{12}, \\space C_{21}\\space \\& \\space C_{22}\n\nMerge\n\nOnce we have computed the output, we return value to previous recursive call.\n\nThis way we are merging the matrix back to its  n \\times n  form.\n\nBase Case\n\nHere, we have base case of  2 \\times 2 , where we stop dividing & start conquering.","type":"content","url":"/chapter-2-4-strassen-matrix-multiplication","position":1},{"hierarchy":{"lvl1":"Strassen’s Matrix Multiplication","lvl2":"Formula of Multiplications and Constants"},"type":"lvl2","url":"/chapter-2-4-strassen-matrix-multiplication#formula-of-multiplications-and-constants","position":2},{"hierarchy":{"lvl1":"Strassen’s Matrix Multiplication","lvl2":"Formula of Multiplications and Constants"},"content":"Strassen Multiplication aims for:\n$$\n\nA \\times B =\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix}\n\n\\times\\begin{bmatrix}\nb_{11} & b_{12} \\\\\nb_{21} & b_{22}\n\\end{bmatrix}\n\n=\\begin{bmatrix}\nC_{11} & C_{12} \\\\\nC_{21} & C_{22}\n\\end{bmatrix}\n\n$$","type":"content","url":"/chapter-2-4-strassen-matrix-multiplication#formula-of-multiplications-and-constants","position":3},{"hierarchy":{"lvl1":"License"},"type":"lvl1","url":"/license","position":0},{"hierarchy":{"lvl1":"License"},"content":"Copyright © 2026 Abhishek Roka. All rights reserved.\n\nThis work, including but not limited to all text, explanations,\nalgorithms, code snippets, notebooks, diagrams, figures, and\nsupplementary materials (collectively, “the Work”), is protected\nby copyright law.\n\nPermission is hereby granted to any individual to view, read, and\nuse the Work strictly for personal, academic, or non-commercial\neducational purposes.\n\nThe following activities are strictly prohibited without prior\nwritten permission from the copyright holder:\n\nCommercial use of any kind, including but not limited to:\n\nSelling the Work in whole or in part\n\nIncluding the Work in paid courses, training programs, or workshops\n\nUsing the Work in commercial products, services, or platforms\n\nMonetizing the Work through subscriptions, advertisements, or sponsorships\n\nRedistribution or republication, including but not limited to:\n\nReposting the Work on other websites or platforms\n\nPublishing the Work under another name\n\nPrinting and distributing copies for sale or profit\n\nCreation of derivative works for commercial purposes, including:\n\nModified versions of the text or code\n\nTranslations\n\nAdaptations into videos, slides, or other media intended for commercial use\n\nNon-commercial forks, quotations, or references for academic discussion\nor review are permitted, provided proper attribution is given and no\nmonetary benefit is derived.\n\nAny use outside the scope of this license requires explicit prior\nwritten permission from the copyright holder.\n\nTHE WORK IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT.\n\nFor permissions, contact:\n\n\n2abhishek00roka2@gmail​.com","type":"content","url":"/license","position":1},{"hierarchy":{"lvl1":"Preface"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Preface"},"content":"Hello, World!","type":"content","url":"/","position":1}]}